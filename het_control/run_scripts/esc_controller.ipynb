{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1453821b",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1786c7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/rl/torchrl/data/replay_buffers/samplers.py:23: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. If you installed TorchRL from PyPI, please report the bug on TorchRL github. If you installed TorchRL locally and/or in development mode, check that you have all the required compiling packages.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "# Hydra\n",
    "import hydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# WandB / Logging\n",
    "import wandb\n",
    "\n",
    "# BenchMARL\n",
    "import benchmarl.models\n",
    "from benchmarl.algorithms import *\n",
    "from benchmarl.environments import VmasTask\n",
    "from benchmarl.experiment import Experiment\n",
    "from benchmarl.hydra_config import (\n",
    "    load_algorithm_config_from_hydra,\n",
    "    load_experiment_config_from_hydra,\n",
    "    load_task_config_from_hydra,\n",
    "    load_model_config_from_hydra,\n",
    ")\n",
    "from benchmarl.experiment.callback import Callback\n",
    "\n",
    "# Het-Control\n",
    "from het_control.callback import *\n",
    "from het_control.environments.vmas import render_callback\n",
    "from het_control.models.het_control_mlp_empirical import (\n",
    "    HetControlMlpEmpiricalConfig,\n",
    "    HetControlMlpEmpirical,\n",
    ")\n",
    "from het_control.callbacks.sndESLogger import TrajectorySNDLoggerCallback\n",
    "from het_control.callbacks.utils import *\n",
    "from het_control.snd import compute_behavioral_distance\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "import torch\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from typing import List, Dict, Any, Callable, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b0c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving original WandB init function...\n"
     ]
    }
   ],
   "source": [
    "unique_id = f\"AD2C_Eval_{int(time.time())}\"\n",
    "\n",
    "if not hasattr(wandb, \"_custom_orig_init\"):\n",
    "    print(\"Saving original WandB init function...\")\n",
    "    wandb._custom_orig_init = wandb.init\n",
    "\n",
    "def forced_wandb_init(*args, **kwargs):\n",
    "    print(f\"\\n--- INTERCEPTING WANDB INIT ---\")\n",
    "    \n",
    "    # Force the new ID and Name\n",
    "    kwargs['id'] = unique_id\n",
    "    kwargs['name'] = unique_id\n",
    "    \n",
    "    # Force \"New Run\" behavior\n",
    "    kwargs['resume'] = \"allow\" \n",
    "    kwargs['reinit'] = True\n",
    "    \n",
    "    print(f\"Forced ID: {unique_id}\")\n",
    "    print(f\"-------------------------------\\n\")\n",
    "    \n",
    "    # We always call the SAVED original function, not the current one\n",
    "    return wandb._custom_orig_init(*args, **kwargs)\n",
    "\n",
    "# Apply the patch\n",
    "wandb.init = forced_wandb_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8da2e",
   "metadata": {},
   "source": [
    "## SND Visualization Plot\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53853c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "import torch\n",
    "import networkx as nx  # Required for the Graph Visualizer\n",
    "\n",
    "class SNDHeatmapVisualizer:\n",
    "    def __init__(self, key_name=\"Visuals/SND_Heatmap\"):\n",
    "        self.key_name = key_name\n",
    "\n",
    "    def generate(self, snd_matrix, step_count):\n",
    "        # snd_matrix is now GUARANTEED to be a clean 2D Numpy array\n",
    "        n_agents = snd_matrix.shape[0]\n",
    "        agent_labels = [f\"Agent {i+1}\" for i in range(n_agents)]\n",
    "        \n",
    "        # Calculate SND value\n",
    "        iu = np.triu_indices(n_agents, k=1)\n",
    "        if len(iu[0]) > 0:\n",
    "            snd_value = float(np.mean(snd_matrix[iu]))\n",
    "        else:\n",
    "            snd_value = 0.0\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "        im = ax.imshow(\n",
    "            snd_matrix,\n",
    "            cmap=\"viridis\",\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=0, vmax=3 \n",
    "        )\n",
    "\n",
    "        ax.set_title(f\"SND: {snd_value:.3f}  –  Step {step_count}\")\n",
    "\n",
    "        ax.set_xticks(np.arange(n_agents))\n",
    "        ax.set_yticks(np.arange(n_agents))\n",
    "        ax.set_xticklabels(agent_labels)\n",
    "        ax.set_yticklabels(agent_labels)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "\n",
    "        fig.colorbar(im, ax=ax, label=\"Distance\")\n",
    "\n",
    "        for i in range(n_agents):\n",
    "            for j in range(n_agents):\n",
    "                val = snd_matrix[i, j]\n",
    "                # Dynamic text color for visibility\n",
    "                text_color = \"white\" if val < 1.0 else \"black\"\n",
    "                ax.text(\n",
    "                    j, i, f\"{val:.2f}\",\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=text_color,\n",
    "                    fontsize=9, fontweight=\"bold\"\n",
    "                )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        img = wandb.Image(fig)\n",
    "        plt.close(fig)\n",
    "        return {self.key_name: img}\n",
    "\n",
    "\n",
    "class SNDBarChartVisualizer:\n",
    "    def __init__(self, key_name=\"Visuals/SND_BarChart\"):\n",
    "        self.key_name = key_name\n",
    "\n",
    "    def generate(self, snd_matrix, step_count):\n",
    "        n_agents = snd_matrix.shape[0]\n",
    "        \n",
    "        # Create pairs i < j\n",
    "        pairs = [(i, j) for i in range(n_agents) for j in range(i + 1, n_agents)]\n",
    "        if not pairs:\n",
    "            return {}\n",
    "\n",
    "        pair_values = [float(snd_matrix[i, j]) for i, j in pairs]\n",
    "        pair_labels = [f\"A{i+1}-A{j+1}\" for i, j in pairs]\n",
    "\n",
    "        snd_value = float(np.mean(pair_values))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        bars = ax.bar(pair_labels, pair_values, color=\"teal\")\n",
    "\n",
    "        ax.set_title(f\"SND: {snd_value:.3f}  –  Step {step_count}\")\n",
    "        ax.set_ylabel(\"Distance\")\n",
    "        ax.set_ylim(0, 3)\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        ax.bar_label(bars, fmt=\"%.2f\", padding=3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        img = wandb.Image(fig)\n",
    "        plt.close(fig)\n",
    "        return {self.key_name: img}\n",
    "\n",
    "\n",
    "class SNDGraphVisualizer:\n",
    "    def __init__(self, key_name=\"Visuals/SND_NetworkGraph\"):\n",
    "        self.key_name = key_name\n",
    "\n",
    "    def generate(self, snd_matrix, step_count):\n",
    "        n_agents = snd_matrix.shape[0]\n",
    "\n",
    "        pairs = [(i, j) for i in range(n_agents) for j in range(i + 1, n_agents)]\n",
    "        if not pairs:\n",
    "            return {}\n",
    "\n",
    "        pair_values = [float(snd_matrix[i, j]) for i, j in pairs]\n",
    "        snd_value = float(np.mean(pair_values))\n",
    "\n",
    "        fig = plt.figure(figsize=(7, 7))\n",
    "        G = nx.Graph()\n",
    "\n",
    "        for i, j in pairs:\n",
    "            G.add_edge(i, j, weight=float(snd_matrix[i, j]))\n",
    "\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=750, node_color='lightblue')\n",
    "        \n",
    "        label_mapping = {i: f\"A{i+1}\" for i in range(n_agents)}\n",
    "        nx.draw_networkx_labels(G, pos, labels=label_mapping, font_size=12, font_weight='bold')\n",
    "\n",
    "        edges = nx.draw_networkx_edges(\n",
    "            G, pos,\n",
    "            edge_color=weights,\n",
    "            edge_cmap=plt.cm.viridis,\n",
    "            width=2,\n",
    "            edge_vmin=0, edge_vmax=3\n",
    "        )\n",
    "\n",
    "        edge_labels = {(i, j): f\"{snd_matrix[i, j]:.2f}\" for i, j in pairs}\n",
    "        nx.draw_networkx_edge_labels(\n",
    "            G, pos, edge_labels=edge_labels,\n",
    "            font_color='black', font_size=9, font_weight='bold'\n",
    "        )\n",
    "\n",
    "        plt.colorbar(edges, label='Distance')\n",
    "        plt.title(f\"SND: {snd_value:.3f}  –  Step {step_count}\", fontsize=14)\n",
    "        plt.axis('off')\n",
    "\n",
    "        img = wandb.Image(fig)\n",
    "        plt.close(fig)\n",
    "        return {self.key_name: img}\n",
    "\n",
    "\n",
    "class SNDVisualizationManager:\n",
    "    \"\"\"\n",
    "    Manages the individual visualizers and handles ALL data cleaning centrally.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.visualizers = [\n",
    "            SNDHeatmapVisualizer(),\n",
    "            SNDBarChartVisualizer(),\n",
    "            SNDGraphVisualizer()\n",
    "        ]\n",
    "\n",
    "    def _prepare_matrix(self, snd_matrix):\n",
    "        \"\"\"\n",
    "        Robustly converts and reshapes matrix.\n",
    "        Fixes crash by Symmetrizing (Broadcasting) BEFORE accessing diagonals.\n",
    "        \"\"\"\n",
    "        # 1. Convert to Numpy\n",
    "        if hasattr(snd_matrix, \"detach\"):\n",
    "            snd_matrix = snd_matrix.detach().cpu().numpy()\n",
    "        elif not isinstance(snd_matrix, np.ndarray):\n",
    "            snd_matrix = np.array(snd_matrix)\n",
    "\n",
    "        # 2. \"Peel\" dimensions until we hit 2D\n",
    "        # This turns (1, 2, 2) -> (2, 2) and (1, 2, 1) -> (2, 1)\n",
    "        while snd_matrix.ndim > 2:\n",
    "            snd_matrix = snd_matrix[0]\n",
    "\n",
    "        # 3. Handle 1D edge case (if squeeze happened upstream)\n",
    "        if snd_matrix.ndim == 1:\n",
    "            # Try to reshape to square, or expand dims\n",
    "            size = snd_matrix.shape[0]\n",
    "            n_agents = int(np.sqrt(size))\n",
    "            if n_agents * n_agents == size:\n",
    "                snd_matrix = snd_matrix.reshape(n_agents, n_agents)\n",
    "            else:\n",
    "                # Treat as column vector (N, 1)\n",
    "                snd_matrix = snd_matrix[:, None]\n",
    "\n",
    "        # 4. Create copy\n",
    "        snd_matrix = snd_matrix.copy()\n",
    "\n",
    "        # 5. FIX: Enforce Symmetry FIRST\n",
    "        # If input is (2, 1), this line broadcasts it: (2, 1) + (1, 2) = (2, 2)\n",
    "        # This automatically \"expands\" the missing dimension.\n",
    "        snd_matrix = (snd_matrix + snd_matrix.T) / 2.0\n",
    "\n",
    "        # 6. NOW set diagonals (Safe because matrix is guaranteed square now)\n",
    "        n = snd_matrix.shape[0]\n",
    "        if n > 0:\n",
    "            for i in range(n):\n",
    "                snd_matrix[i, i] = 0.0\n",
    "        \n",
    "        return snd_matrix\n",
    "\n",
    "    def generate_all(self, snd_matrix, step_count):\n",
    "        # Clean the matrix ONCE here\n",
    "        clean_matrix = self._prepare_matrix(snd_matrix)\n",
    "        \n",
    "        all_plots = {}\n",
    "        for visualizer in self.visualizers:\n",
    "            try:\n",
    "                # Pass the clean matrix to all visualizers\n",
    "                plots = visualizer.generate(clean_matrix, step_count)\n",
    "                all_plots.update(plots)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating {visualizer.__class__.__name__}: {e}\")\n",
    "                # Optional: Print shape to help debug if it fails again\n",
    "                print(f\"Failed Matrix Shape: {clean_matrix.shape}\")\n",
    "        return all_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6262e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNDVisualizerCallback(Callback):\n",
    "    \"\"\"\n",
    "    Computes the SND matrix and uses the Manager to log visualizations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.control_group = None\n",
    "        self.model = None\n",
    "        # Initialize the manager that holds the 3 plot classes\n",
    "        self.viz_manager = SNDVisualizationManager()\n",
    "\n",
    "    def on_setup(self):\n",
    "        \"\"\"Auto-detects the agent group and initializes the model wrapper.\"\"\"\n",
    "        if not self.experiment.group_policies:\n",
    "            print(\"\\nWARNING: No group policies found. SND Visualizer disabled.\\n\")\n",
    "            return\n",
    "\n",
    "        self.control_group = list(self.experiment.group_policies.keys())[0]\n",
    "        policy = self.experiment.group_policies[self.control_group]\n",
    "        \n",
    "        # Ensure 'get_het_model' is imported or available in this scope\n",
    "        self.model = get_het_model(policy)\n",
    "\n",
    "        if self.model is None:\n",
    "             print(f\"\\nWARNING: Could not extract HetModel for group '{self.control_group}'. Visualizer disabled.\\n\")\n",
    "\n",
    "    def _get_agent_actions_for_rollout(self, rollout):\n",
    "        \"\"\"Helper to run the forward pass and get actions for SND computation.\"\"\"\n",
    "        obs = rollout.get((self.control_group, \"observation\"))\n",
    "        actions = []\n",
    "        for i in range(self.model.n_agents):\n",
    "            temp_td = TensorDict(\n",
    "                {(self.control_group, \"observation\"): obs},\n",
    "                batch_size=obs.shape[:-1]\n",
    "            )\n",
    "            action_td = self.model._forward(temp_td, agent_index=i, compute_estimate=False)\n",
    "            actions.append(action_td.get(self.model.out_key))\n",
    "        return actions\n",
    "\n",
    "    def on_evaluation_end(self, rollouts: List[TensorDict]):\n",
    "        \"\"\"Runs at the end of evaluation to compute SND and log plots.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "\n",
    "        logs_to_push = {}\n",
    "        first_rollout_snd_matrix = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, r in enumerate(rollouts):\n",
    "                # We only need the matrix from the first rollout for clean visualization\n",
    "                if i > 0: \n",
    "                    break\n",
    "\n",
    "                agent_actions = self._get_agent_actions_for_rollout(r)\n",
    "                \n",
    "                # Ensure 'compute_behavioral_distance' is imported/available\n",
    "                pairwise_distances_tensor = compute_behavioral_distance(agent_actions, just_mean=False)\n",
    "                \n",
    "                if pairwise_distances_tensor.ndim > 2:\n",
    "                    pairwise_distances_tensor = pairwise_distances_tensor.mean(dim=0)\n",
    "\n",
    "                first_rollout_snd_matrix = pairwise_distances_tensor.cpu().numpy()\n",
    "\n",
    "        # Generate and Log Visualizations via the Manager\n",
    "        if first_rollout_snd_matrix is not None:\n",
    "            visual_logs = self.viz_manager.generate_all(\n",
    "                snd_matrix=first_rollout_snd_matrix, \n",
    "                step_count=self.experiment.n_iters_performed\n",
    "            )\n",
    "            logs_to_push.update(visual_logs)\n",
    "            \n",
    "            # Update the logger\n",
    "            self.experiment.logger.log(logs_to_push, step=self.experiment.n_iters_performed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb8f36",
   "metadata": {},
   "source": [
    "## ESC Controller\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d7e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from typing import Dict, Any, List, Tuple\n",
    "from benchmarl.experiment.callback import Callback\n",
    "from het_control.models.het_control_mlp_empirical import HetControlMlpEmpirical\n",
    "from tensordict import TensorDictBase\n",
    "\n",
    "# --- 1. Signal Processing Components ---\n",
    "\n",
    "class FirstOrderLPF:\n",
    "    \"\"\"Standard First-Order Low Pass Filter.\"\"\"\n",
    "    def __init__(self, sampling_period: float, cutoff_freq: float, initial_value: float = 0.0):\n",
    "        self.alpha = np.exp(-sampling_period * cutoff_freq)\n",
    "        self.prev_val = float(initial_value)\n",
    "\n",
    "    def apply(self, input_val: float) -> float:\n",
    "        output = self.alpha * self.prev_val + (1 - self.alpha) * input_val\n",
    "        self.prev_val = output\n",
    "        return output\n",
    "\n",
    "class FirstOrderHPF:\n",
    "    \"\"\"First-Order High Pass Filter using Tustin approximation.\"\"\"\n",
    "    def __init__(self, sampling_period: float, cutoff_freq: float, initial_input: float = 0.0, initial_output: float = 0.0):\n",
    "        dt = sampling_period\n",
    "        wc = cutoff_freq\n",
    "        self.a1 = dt * wc + 2.0\n",
    "        self.b1 = dt * wc - 2.0\n",
    "        \n",
    "        self.u_prev = float(initial_input)\n",
    "        self.y_prev = float(initial_output)\n",
    "\n",
    "    def apply(self, input_val: float) -> float:\n",
    "        output = (1.0 / self.a1) * (-self.b1 * self.y_prev + 2.0 * (input_val - self.u_prev))\n",
    "        self.u_prev = input_val\n",
    "        self.y_prev = output\n",
    "        return output\n",
    "\n",
    "class PhaseGenerator:\n",
    "    \"\"\"\n",
    "    Handles the dither signal generation (sin(wt)).\n",
    "    Manages the phase 'wt' and keeps it within [0, 2pi].\n",
    "    \"\"\"\n",
    "    def __init__(self, frequency: float, magnitude: float, sampling_period: float):\n",
    "        self.freq = frequency        # rad/s\n",
    "        self.mag = magnitude\n",
    "        self.dt = sampling_period\n",
    "        self.wt = 0.0\n",
    "\n",
    "    def step(self) -> Tuple[float, float]:\n",
    "        \"\"\"Updates phase and returns (carrier_signal, dither_value).\"\"\"\n",
    "        carrier = np.sin(self.wt)\n",
    "        dither = self.mag * carrier\n",
    "        \n",
    "        # Update phase\n",
    "        self.wt += self.freq * self.dt\n",
    "        if self.wt > 2 * np.pi:\n",
    "            self.wt -= 2 * np.pi\n",
    "            \n",
    "        return carrier, dither\n",
    "\n",
    "class GradientEstimator:\n",
    "    \"\"\"\n",
    "    Demodulates the signal (Cost * sin(wt)) and applies Low Pass Filtering.\n",
    "    Also handles the 'Adapter' logic (RMS normalization).\n",
    "    \"\"\"\n",
    "    def __init__(self, lpf_cutoff: float, sampling_period: float, use_adapter: bool = True):\n",
    "        self.lpf = FirstOrderLPF(sampling_period, lpf_cutoff)\n",
    "        self.use_adapter = use_adapter\n",
    "        \n",
    "        # Adaptation state\n",
    "        self.m2 = 0.0       # Second moment estimate\n",
    "        self.b2 = 0.8       # Forgetting factor for variance\n",
    "        self.epsilon = 1e-8\n",
    "        self.grad_mag = 0.0\n",
    "        self.gradient_raw = 0.0\n",
    "\n",
    "    def estimate(self, high_passed_cost: float, carrier_signal: float) -> float:\n",
    "        # 1. Demodulate\n",
    "        demodulated = high_passed_cost * carrier_signal\n",
    "        \n",
    "        # 2. Filter to get DC component (gradient)\n",
    "        gradient_raw = self.lpf.apply(demodulated)\n",
    "        \n",
    "        # 3. Adaptation (Normalization)\n",
    "        self.m2 = self.b2 * self.m2 + (1 - self.b2) * (gradient_raw ** 2)\n",
    "        self.grad_mag = np.sqrt(self.m2)\n",
    "        \n",
    "        if self.use_adapter:\n",
    "            # Normalize gradient by its RMS value\n",
    "            return gradient_raw / (self.grad_mag + self.epsilon)\n",
    "        \n",
    "        return gradient_raw\n",
    "\n",
    "class Integrator:\n",
    "    \"\"\"\n",
    "    Integrates the estimated gradient to update the parameter theta.\n",
    "    Handles Gain Scheduling and Saturation (Min/Max limits).\n",
    "    \"\"\"\n",
    "    def __init__(self, base_gain: float, initial_value: float, min_val: float, dt: float):\n",
    "        self.gain = base_gain\n",
    "        self.integral = 0.0\n",
    "        self.initial_value = initial_value\n",
    "        self.min_val = min_val\n",
    "        self.dt = dt\n",
    "        \n",
    "        # Gain scheduling parameters\n",
    "        self.high_gain = -0.025\n",
    "        self.threshold = 0.2\n",
    "        self.use_gain_scheduling = False # Can be enabled via setter\n",
    "\n",
    "    def set_gain_scheduling(self, enabled: bool):\n",
    "        self.use_gain_scheduling = enabled\n",
    "\n",
    "    def step(self, gradient: float, gradient_magnitude: float = 0.0) -> float:\n",
    "        # 1. Determine Gain\n",
    "        current_gain = self.gain\n",
    "        if self.use_gain_scheduling:\n",
    "            if gradient_magnitude > self.threshold:\n",
    "                current_gain = self.high_gain\n",
    "        \n",
    "        # 2. Integrate: theta = integral(gain * grad)\n",
    "        self.integral += current_gain * gradient * self.dt\n",
    "        \n",
    "        # 3. Calculate Raw Setpoint\n",
    "        setpoint_raw = self.initial_value + self.integral\n",
    "        \n",
    "        # 4. Clamp/Saturate\n",
    "        setpoint = max(setpoint_raw, self.min_val)\n",
    "        \n",
    "        # 5. Anti-windup: if clamped, correct the integral to match the clamp\n",
    "        if setpoint < self.min_val:\n",
    "            self.integral = self.min_val - self.initial_value\n",
    "            \n",
    "        return setpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec750ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESController:\n",
    "    \"\"\"\n",
    "    Orchestrates the ESC components.\n",
    "    Inputs: Cost (J)\n",
    "    Outputs: Control Signal (theta + dither), and debug logs.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 sampling_period: float,\n",
    "                 perturb_freq: float,\n",
    "                 perturb_mag: float,\n",
    "                 integrator_gain: float,\n",
    "                 initial_val: float,\n",
    "                 hpf_cutoff: float,\n",
    "                 lpf_cutoff: float,\n",
    "                 use_adapter: bool):\n",
    "\n",
    "        # 1. Initialize Components\n",
    "        self.hpf = FirstOrderHPF(sampling_period, hpf_cutoff)\n",
    "        \n",
    "        self.perturbation = PhaseGenerator(perturb_freq, perturb_mag, sampling_period)\n",
    "        \n",
    "        self.grad_estimator = GradientEstimator(lpf_cutoff, sampling_period, use_adapter)\n",
    "        \n",
    "        self.integrator = Integrator(integrator_gain, initial_val, min_val=0.0, dt=sampling_period)\n",
    "        # Enable the gain scheduling logic you had in your original code\n",
    "        self.integrator.set_gain_scheduling(use_adapter) \n",
    "\n",
    "    def update(self, cost: float) -> Dict[str, float]:\n",
    "        \"\"\"\n",
    "        Run one step of the ESC loop.\n",
    "        Returns a dictionary containing the output and intermediate values for logging.\n",
    "        \"\"\"\n",
    "        # A. High Pass Filter the Cost\n",
    "        y_hpf = self.hpf.apply(cost)\n",
    "\n",
    "        # B. Get Perturbation (Carrier and Dither)\n",
    "        carrier, dither = self.perturbation.step()\n",
    "\n",
    "        # C. Estimate Gradient (Demodulate -> LPF -> Adapt)\n",
    "        gradient = self.grad_estimator.estimate(y_hpf, carrier)\n",
    "        grad_mag = self.grad_estimator.grad_mag # Retrieve internal state for scheduling\n",
    "\n",
    "        # D. Update Setpoint (Integrator)\n",
    "        theta_hat = self.integrator.step(gradient, grad_mag)\n",
    "\n",
    "        # E. Final Output\n",
    "        output_signal = theta_hat + dither\n",
    "\n",
    "        return {\n",
    "            \"output\": output_signal,\n",
    "            \"theta_hat\": theta_hat,\n",
    "            \"dither\": dither,\n",
    "            \"gradient\": gradient,\n",
    "            \"cost_hpf\": y_hpf,\n",
    "            \"grad_mag\": grad_mag,\n",
    "            \"lpf_output\": self.grad_estimator.gradient_raw,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372f1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESCallback(Callback):\n",
    "    \"\"\"\n",
    "    BenchMARL Callback that wraps the modular ESController.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        control_group: str,\n",
    "        initial_snd: float,\n",
    "        dither_magnitude: float,\n",
    "        dither_frequency_rad_s: float,\n",
    "        integral_gain: float,\n",
    "        high_pass_cutoff_rad_s: float,\n",
    "        low_pass_cutoff_rad_s: float,\n",
    "        use_adapter: bool = True,\n",
    "        sampling_period: float = 1.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.control_group = control_group\n",
    "        self.initial_snd = initial_snd\n",
    "        \n",
    "        # Save params to initialize controller later\n",
    "        self.esc_config = {\n",
    "            \"sampling_period\": sampling_period,\n",
    "            \"perturb_freq\": dither_frequency_rad_s,\n",
    "            \"perturb_mag\": dither_magnitude,\n",
    "            \"integrator_gain\": integral_gain,\n",
    "            \"initial_val\": initial_snd,\n",
    "            \"hpf_cutoff\": high_pass_cutoff_rad_s,\n",
    "            \"lpf_cutoff\": low_pass_cutoff_rad_s,\n",
    "            \"use_adapter\": use_adapter\n",
    "        }\n",
    "        \n",
    "        self.model = None\n",
    "        self.controller = None\n",
    "\n",
    "    def on_setup(self):\n",
    "        \"\"\"Initialize controller and validate model presence.\"\"\"\n",
    "        # self.experiment.logger.log_hparams({\n",
    "        #     \"control_group\": self.control_group,\n",
    "        #     **self.esc_config\n",
    "        # })\n",
    "\n",
    "        if self.control_group not in self.experiment.group_policies:\n",
    "            print(f\"WARNING: Group '{self.control_group}' not found.\")\n",
    "            return\n",
    "\n",
    "        policy = self.experiment.group_policies[self.control_group]\n",
    "        # Assuming get_het_model is defined in your utils\n",
    "        self.model = get_het_model(policy) \n",
    "\n",
    "        if isinstance(self.model, HetControlMlpEmpirical):\n",
    "            print(f\"✅ ESC Initialized for '{self.control_group}'\")\n",
    "            self.controller = ESController(**self.esc_config)\n",
    "            self.model.desired_snd[:] = float(self.initial_snd)\n",
    "        else:\n",
    "            print(f\"WARNING: Compatible model not found for '{self.control_group}'.\")\n",
    "\n",
    "    def on_evaluation_end(self, rollouts: List[TensorDictBase]):\n",
    "        if self.model is None or self.controller is None:\n",
    "            return\n",
    "\n",
    "        # 1. Calculate Cost (Negative Reward)\n",
    "        episode_rewards = []\n",
    "        with torch.no_grad():\n",
    "            for r in rollouts:\n",
    "                reward_key = ('next', self.control_group, 'reward')\n",
    "                if reward_key in r.keys(include_nested=True):\n",
    "                    episode_rewards.append(r.get(reward_key).sum().item())\n",
    "                else:\n",
    "                    episode_rewards.append(0.0)\n",
    "\n",
    "        if not episode_rewards:\n",
    "            return\n",
    "\n",
    "        reward_mean = np.mean(episode_rewards)\n",
    "        reward_mean = np.clip(reward_mean, -4.0, 4.0)\n",
    "        cost = -reward_mean \n",
    "\n",
    "        # 2. Update Controller\n",
    "        results = self.controller.update(cost)\n",
    "        \n",
    "        # 3. Apply new parameter to PyTorch Model\n",
    "        new_snd = results[\"output\"]\n",
    "        previous_snd = self.model.desired_snd.item()\n",
    "        \n",
    "        # Ensure we don't pass negative values to the model even with dither\n",
    "        final_snd_val = max(0.0, new_snd) \n",
    "        self.model.desired_snd[:] = float(final_snd_val)\n",
    "\n",
    "        print(f\"[ESC] Updated SND: {final_snd_val:.4f} (Reward: {reward_mean:.3f})\")\n",
    "\n",
    "        # 4. Log Metrics\n",
    "        logs = {\n",
    "            \"esc/mean_reward\": reward_mean,\n",
    "            \"esc/cost\": cost,\n",
    "            \"esc/diversity_output\": results[\"output\"],\n",
    "            \"esc/diversity_setpoint\": results[\"theta_hat\"],\n",
    "            \"esc/gradient_estimate\": results[\"gradient\"],\n",
    "            \"esc/hpf_output\": results[\"cost_hpf\"],\n",
    "            \"esc/lpf_output\": results[\"lpf_output\"],\n",
    "            \"esc/m2_sqrt\": results[\"grad_mag\"],\n",
    "            \"esc/update_step\": results[\"output\"] - previous_snd\n",
    "        }\n",
    "        self.experiment.logger.log(logs, step=self.experiment.n_iters_performed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a910f640",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6e30767",
   "metadata": {},
   "source": [
    "## Env Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877a397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. EXPERIMENT LOGIC\n",
    "\n",
    "def setup(task_name):\n",
    "    benchmarl.models.model_config_registry.update(\n",
    "        {\n",
    "            \"hetcontrolmlpempirical\": HetControlMlpEmpiricalConfig,\n",
    "        }\n",
    "    )\n",
    "    if task_name == \"vmas/navigation\":\n",
    "        # Set the render callback for the navigation case study\n",
    "        VmasTask.render_callback = render_callback\n",
    "\n",
    "def get_experiment(cfg: DictConfig) -> Experiment:\n",
    "    hydra_choices = HydraConfig.get().runtime.choices\n",
    "    task_name = hydra_choices.task\n",
    "    algorithm_name = hydra_choices.algorithm\n",
    "\n",
    "    setup(task_name)\n",
    "\n",
    "    print(f\"\\nAlgorithm: {algorithm_name}, Task: {task_name}\")\n",
    "    # print(\"\\nLoaded config:\\n\") # Optional: Commented out to reduce clutter\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    algorithm_config = load_algorithm_config_from_hydra(cfg.algorithm)\n",
    "    experiment_config = load_experiment_config_from_hydra(cfg.experiment)\n",
    "    task_config = load_task_config_from_hydra(cfg.task, task_name)\n",
    "    critic_model_config = load_model_config_from_hydra(cfg.critic_model)\n",
    "    model_config = load_model_config_from_hydra(cfg.model)\n",
    "\n",
    "    if isinstance(algorithm_config, (MappoConfig, IppoConfig, MasacConfig, IsacConfig)):\n",
    "        model_config.probabilistic = True\n",
    "        model_config.scale_mapping = algorithm_config.scale_mapping\n",
    "        algorithm_config.scale_mapping = (\n",
    "            \"relu\"  # The scaling of std_dev will be done in the model\n",
    "        )\n",
    "    else:\n",
    "        model_config.probabilistic = False\n",
    "\n",
    "    experiment = Experiment(\n",
    "        task=task_config,\n",
    "        algorithm_config=algorithm_config,\n",
    "        model_config=model_config,\n",
    "        critic_model_config=critic_model_config,\n",
    "        seed=cfg.seed,\n",
    "        config=experiment_config,\n",
    "        callbacks=[\n",
    "            SndCallback(),\n",
    "            ESCallback(\n",
    "                control_group=\"agents\",\n",
    "                initial_snd=0.0,\n",
    "                dither_magnitude=0.25,            \n",
    "                dither_frequency_rad_s=1.0,\n",
    "                integral_gain=-0.01,             \n",
    "                high_pass_cutoff_rad_s=1.0,\n",
    "                low_pass_cutoff_rad_s=1.0,\n",
    "                sampling_period=1.0,\n",
    "                use_adapter=True,               \n",
    "            ),\n",
    "            SNDVisualizerCallback(),\n",
    "            # TrajectorySNDLoggerCallback(control_group=\"agents\"),\n",
    "            NormLoggerCallback(),\n",
    "            ActionSpaceLoss(\n",
    "                use_action_loss=cfg.use_action_loss, action_loss_lr=cfg.action_loss_lr\n",
    "            ),\n",
    "        ]\n",
    "        + (\n",
    "            [\n",
    "                TagCurriculum(\n",
    "                    cfg.simple_tag_freeze_policy_after_frames,\n",
    "                    cfg.simple_tag_freeze_policy,\n",
    "                )\n",
    "            ]\n",
    "            if task_name == \"vmas/simple_tag\"\n",
    "            else []\n",
    "        ),\n",
    "    )\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2e613",
   "metadata": {},
   "source": [
    "## Runner Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d0405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from: /home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\n",
      "Running with SND: 0.0\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- INTERCEPTING WANDB INIT ---\n",
      "Forced ID: AD2C_Eval_1764922658\n",
      "-------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvarp\u001b[0m (\u001b[33msvarp-university-of-massachusetts-lowell\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__aa14fb39_25_12_05-03_17_42/wandb/run-20251205_031745-AD2C_Eval_1764922658</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_Eval_1764922658' target=\"_blank\">AD2C_Eval_1764922658</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_Eval_1764922658' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_Eval_1764922658</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ESC Initialized for 'agents'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.0000 (Reward: -0.326)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.5083748698234558:   0%|          | 1/200 [00:28<1:34:23, 28.46s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.2327 (Reward: 0.541)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.1288624107837677:   1%|          | 2/200 [00:52<1:25:49, 26.01s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.2994 (Reward: 1.253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.31784185767173767:   2%|▏         | 3/200 [01:21<1:28:50, 27.06s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.1294 (Reward: 1.430)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.5990716814994812:   2%|▏         | 4/200 [01:50<1:31:37, 28.05s/it] /home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.0000 (Reward: -0.202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.6659323573112488:   2%|▎         | 5/200 [02:18<1:30:55, 27.98s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.0000 (Reward: 0.447)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.1500786691904068:   3%|▎         | 6/200 [02:44<1:28:15, 27.29s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.0750 (Reward: 1.122)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.32040777802467346:   4%|▎         | 7/200 [03:10<1:26:40, 26.95s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.3332 (Reward: 1.823)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.7275105714797974:   4%|▍         | 8/200 [03:39<1:28:14, 27.57s/it] /home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.4277 (Reward: 1.548)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.5936908721923828:   4%|▍         | 9/200 [04:10<1:31:00, 28.59s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.2889 (Reward: 1.576)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.5970005393028259:   5%|▌         | 10/200 [04:41<1:33:06, 29.40s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.0520 (Reward: 1.464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.554078996181488:   6%|▌         | 11/200 [05:11<1:33:04, 29.55s/it] /home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.0000 (Reward: -2.495)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.8480725288391113:   6%|▌         | 12/200 [05:40<1:32:00, 29.36s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.1365 (Reward: -2.405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -1.5078516006469727:   6%|▋         | 13/200 [06:06<1:28:11, 28.30s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.3956 (Reward: -0.416)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.7897512912750244:   7%|▋         | 14/200 [06:36<1:29:32, 28.88s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.5695 (Reward: 1.014)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.13459524512290955:   8%|▊         | 15/200 [07:05<1:29:00, 28.87s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.4990 (Reward: 0.600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.6463313102722168:   8%|▊         | 16/200 [07:36<1:30:49, 29.62s/it] /home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.2686 (Reward: 0.935)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.4888173043727875:   8%|▊         | 17/200 [08:06<1:30:17, 29.61s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.1066 (Reward: 0.510)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.1580619215965271:   9%|▉         | 18/200 [08:35<1:29:48, 29.61s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.1705 (Reward: -0.024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.4066326320171356:  10%|▉         | 19/200 [09:05<1:29:05, 29.53s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.4024 (Reward: 0.837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = -0.027867821976542473:  10%|█         | 20/200 [09:35<1:29:05, 29.69s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.6147 (Reward: 1.602)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.6368500590324402:  10%|█         | 21/200 [10:04<1:28:30, 29.67s/it]   /home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.5958 (Reward: 0.840)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.8775628209114075:  11%|█         | 22/200 [10:34<1:27:43, 29.57s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.3845 (Reward: 1.232)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.7624181509017944:  12%|█▏        | 23/200 [11:04<1:27:40, 29.72s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.1635 (Reward: 1.623)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.3405820429325104:  12%|█▏        | 24/200 [11:34<1:27:56, 29.98s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.1404 (Reward: 1.587)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.5965247750282288:  12%|█▎        | 25/200 [12:06<1:28:57, 30.50s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.3297 (Reward: 1.691)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.8030226230621338:  13%|█▎        | 26/200 [12:36<1:27:26, 30.15s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ESC] Updated SND: 0.5530 (Reward: 1.684)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mean return = 0.8326122164726257:  14%|█▎        | 27/200 [13:05<1:26:44, 30.08s/it]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"  # Make sure 'navigation_ippo.yaml' exists in the folder above!\n",
    "SAVE_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/\"\n",
    "\n",
    "save_interval = 600000\n",
    "desired_snd = 0.0\n",
    "max_frame = 12000000\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    print(f\"Creating missing directory: {SAVE_PATH}\")\n",
    "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"dummy.py\",\n",
    "    f\"model.desired_snd={desired_snd}\",\n",
    "    f\"experiment.max_n_frames={max_frame}\",\n",
    "    f\"experiment.checkpoint_interval={save_interval}\",\n",
    "    f\"experiment.save_folder={SAVE_PATH}\",\n",
    "    f\"task.agents_with_same_goal=2\",\n",
    "    f\"task.n_agents=2\",\n",
    "]\n",
    "\n",
    "# 3. Define the Hydra wrapper\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def hydra_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Config loaded from: {ABS_CONFIG_PATH}\")\n",
    "    if wandb.run is not None:\n",
    "        print(\"Finishing previous WandB run...\")\n",
    "        wandb.finish()\n",
    "    \n",
    "    print(f\"Running with SND: {cfg.model.desired_snd}\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    experiment.run()\n",
    "    wandb.finish()\n",
    "\n",
    "# 4. Execute safely\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        hydra_experiment()\n",
    "    except SystemExit:\n",
    "        print(\"Experiment finished successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c6b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5311b21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
